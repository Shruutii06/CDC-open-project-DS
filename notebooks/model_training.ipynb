{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa40ec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244482a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/processed/train_clean.csv\")\n",
    "test_df  = pd.read_csv(\"../data/processed/test_clean.csv\")\n",
    "\n",
    "TRAIN_IMG_DIR = \"../data/images/train\"\n",
    "TEST_IMG_DIR  = \"../data/images/test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c26845-6c56-470b-a199-f5002167df63",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std =[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee05aab7-88b4-4245-b8ed-bcb5d9849746",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = nn.Identity()   # removes final classification layer\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de016f27-771c-4c51-a6a6-e50fef476332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_features(df, img_dir):\n",
    "    features = []\n",
    "    ids = []\n",
    "\n",
    "    missing = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            img_path = os.path.join(img_dir, f\"{row['id']}.png\")\n",
    "\n",
    "            if not os.path.exists(img_path):\n",
    "                missing += 1\n",
    "                continue\n",
    "\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            image = img_transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "            embedding = resnet(image)\n",
    "            embedding = embedding.cpu().numpy().flatten()\n",
    "\n",
    "            features.append(embedding)\n",
    "            ids.append(row[\"id\"])\n",
    "\n",
    "    print(f\"Skipped {missing} missing images\")\n",
    "    return np.array(features), ids\n",
    "\n",
    "train_img_features, train_ids = extract_image_features(\n",
    "    train_df, TRAIN_IMG_DIR\n",
    ")\n",
    "\n",
    "print(train_img_features.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9686ddd9-9d75-4cd9-b75f-a11895213e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_features, test_ids = extract_image_features(\n",
    "    test_df, TEST_IMG_DIR\n",
    ")\n",
    "\n",
    "print(test_img_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07972ae0-b0ef-4b35-a107-ee6b95defd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../data/embeddings\", exist_ok=True)\n",
    "\n",
    "np.save(\"../data/embeddings/train_img_features.npy\", train_img_features)\n",
    "np.save(\"../data/embeddings/test_img_features.npy\", test_img_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94d5836-c5ca-437e-bf82-7f35004afae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2d0bc9-2448-4585-93ab-d03d9d9da3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned tabular data\n",
    "train_df = pd.read_csv(\"../data/processed/train_clean.csv\")\n",
    "test_df  = pd.read_csv(\"../data/processed/test_clean.csv\")\n",
    "\n",
    "# Load image embeddings\n",
    "train_img = np.load(\"../data/embeddings/train_img_features.npy\")\n",
    "test_img  = np.load(\"../data/embeddings/test_img_features.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d54c5f2-9c76-45c7-9e33-70e34a62421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert image embeddings to DataFrame\n",
    "train_img_df = pd.DataFrame(train_img)\n",
    "train_img_df[\"id\"] = train_df.iloc[:len(train_img)][\"id\"].values\n",
    "\n",
    "test_img_df = pd.DataFrame(test_img)\n",
    "test_img_df[\"id\"] = test_df.iloc[:len(test_img)][\"id\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a848309-3fe9-40ab-86d7-b337f08e6097",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.merge(train_img_df, on=\"id\", how=\"inner\")\n",
    "test_df  = test_df.merge(test_img_df, on=\"id\", how=\"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26957370-0948-47cb-aedd-7b963b169c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_features = [\n",
    "    \"bedrooms\", \"bathrooms\", \"sqft_living\", \"sqft_lot\",\n",
    "    \"floors\", \"waterfront\", \"view\", \"condition\", \"grade\",\n",
    "    \"sqft_above\", \"sqft_basement\", \"lat\", \"long\",\n",
    "    \"sqft_living15\", \"sqft_lot15\"\n",
    "]\n",
    "\n",
    "X_tab = train_df[tabular_features]\n",
    "y = train_df[\"price\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5cf14e-9b25-48f2-9171-4c134a51413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tab_train, X_tab_val, y_train, y_val = train_test_split(\n",
    "    X_tab, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d63174-98b7-4719-b50e-42f809e8ffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model[A] tabular only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630bf07c-d44d-4dec-b7d9-bee50c42f7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_tab_train_scaled = scaler.fit_transform(X_tab_train)\n",
    "X_tab_val_scaled   = scaler.transform(X_tab_val)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_tab_train_scaled, y_train)\n",
    "\n",
    "y_pred_tab = lr.predict(X_tab_val_scaled)\n",
    "mse_tab = mean_squared_error(y_val, y_pred_tab)\n",
    "rmse_tab = np.sqrt(mse_tab)\n",
    "# rmse_tab = mean_squared_error(y_val, y_pred_tab, squared=False)\n",
    "r2_tab = r2_score(y_val, y_pred_tab)\n",
    "\n",
    "print(\"TABULAR ONLY RMSE:\", rmse_tab)\n",
    "print(\"TABULAR ONLY R²:\", r2_tab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9012519d-5f30-44cd-909b-a7919e811a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_val - y_pred_tab\n",
    "\n",
    "plt.hist(residuals, bins=50)\n",
    "plt.title(\"Residual Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ad9e6b-22e8-49ad-ad39-84cccec57555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_val, y_pred_tab)\n",
    "print(\"mean absolute error(tab) : \",mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b755b70-b9f8-4a0d-a6cf-df3f11cf90db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model [B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510b3af4-f8e5-416d-916f-047a79025a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features = [col for col in train_df.columns if col not in tabular_features + [\"id\", \"price\"]]\n",
    "\n",
    "X_img = train_df[image_features].select_dtypes(include=[\"number\"])\n",
    "X_tab = train_df[tabular_features].select_dtypes(include=[\"number\"])\n",
    "X_multi = np.hstack([\n",
    "    scaler.fit_transform(X_tab),\n",
    "    X_img.values\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc994c7-7b41-47db-a6ae-d97c80f2fa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_tab shape:\", X_tab.shape)\n",
    "print(\"X_img shape:\", X_img.shape)\n",
    "print(\"X_img dtypes:\\n\", X_img.dtypes.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc08f67-5d62-4c83-8b8d-4f89cc016ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_m, X_val_m, y_train, y_val = train_test_split(\n",
    "    X_multi, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbad924-895e-441a-a7b0-41cde92839c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=20,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train_m, y_train)\n",
    "y_pred_multi = rf.predict(X_val_m)\n",
    "\n",
    "# Metrics\n",
    "rmse_multi = np.sqrt(mean_squared_error(y_val, y_pred_multi))\n",
    "r2_multi = r2_score(y_val, y_pred_multi)\n",
    "\n",
    "print(\"MULTIMODAL RMSE:\", rmse_multi)\n",
    "print(\"MULTIMODAL R²:\", r2_multi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a58e65d-76b1-469b-ab95-d6afe3099de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_val - y_pred_multi\n",
    "\n",
    "plt.hist(residuals, bins=50)\n",
    "plt.title(\"Residual Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3088510c-a427-4cd2-a25d-6a8046944290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_val, y_pred_multi)\n",
    "print(\"mean absolute error(multi) : \",mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cffc0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall numpy -y\n",
    "!pip install numpy==1.26.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c50481c-2f28-4f1d-9713-e8414369f8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Phase 6: Explainability with Grad-CAM\n",
    "!pip install opencv-python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde3a379-2df9-41b1-8800-3e6322ed2ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dce02b-1b0d-434b-a4f7-3d6a050ec99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173af4dd-1532-4649-8a9d-ce405ff5e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer = resnet.layer4[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784c2298-d3e6-4df1-acc6-8bb1013088a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self._register_hooks()\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        def forward_hook(module, input, output):\n",
    "            self.activations = output\n",
    "\n",
    "        def backward_hook(module, grad_in, grad_out):\n",
    "            self.gradients = grad_out[0]\n",
    "\n",
    "        self.target_layer.register_forward_hook(forward_hook)\n",
    "        self.target_layer.register_backward_hook(backward_hook)\n",
    "\n",
    "    def generate(self, input_tensor):\n",
    "        output = self.model(input_tensor)\n",
    "        score = output.mean()  # regression proxy\n",
    "        self.model.zero_grad()\n",
    "        score.backward()\n",
    "\n",
    "        weights = self.gradients.mean(dim=[2, 3], keepdim=True)\n",
    "        cam = (weights * self.activations).sum(dim=1)\n",
    "\n",
    "        cam = F.relu(cam)\n",
    "        cam = cam - cam.min()\n",
    "        cam = cam / cam.max()\n",
    "\n",
    "        return cam.squeeze().detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51da378-07ae-4f18-9f63-2f643e4e327a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std =[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "def load_image(path):\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    tensor = img_transform(img).unsqueeze(0).to(device)\n",
    "    return img, tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11181a0-1231-42c7-b131-f25f38542bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradcam = GradCAM(resnet, target_layer)\n",
    "\n",
    "# Pick ANY image (prefer expensive & cheap examples)\n",
    "sample_id = train_df.sample(1)[\"id\"].values[0]\n",
    "img_path = f\"../data/images/train/{sample_id}.png\"\n",
    "\n",
    "original_img, input_tensor = load_image(img_path)\n",
    "cam = gradcam.generate(input_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eef62d-7d7f-48ce-9e9b-ba2a3eb6bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_cam(img, cam):\n",
    "    img = np.array(img)\n",
    "    cam = cv2.resize(cam, (img.shape[1], img.shape[0]))\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "    overlay = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)\n",
    "    return overlay\n",
    "\n",
    "overlay = overlay_cam(original_img, cam)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(overlay)\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Grad-CAM Visualization (ID {sample_id})\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a545f0-b0b7-4199-aa08-8b9f7af9413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8e3f94-ffa9-4da4-9849-5284d3521560",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
